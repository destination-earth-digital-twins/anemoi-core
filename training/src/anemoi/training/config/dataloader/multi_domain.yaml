prefetch_factor: 2
pin_memory: True

# ============
# read_group_size:
#   Form subgroups of model comm groups that read data together.
#   Each reader in the group only reads 1/read_group_size of the data
#   which is then all-gathered between the group.
#   This can reduce CPU memory usage as well as increase dataloader throughput.
#   The number of GPUs per model must be divisible by read_group_size.
#   To disable, set to 1.
# ============
read_group_size: ${hardware.num_gpus_per_model}

num_workers:
  training: 1
  validation: 1
  test: 1
  predict: 1
batch_size:
  training: 1 # generalize to higher batches what? -> bs > 2: graph_label [ARA,ARA] should only be ARA
  validation: 1
  test: 1
  predict: 1

# ============
# Default effective batch_size for training is 16
# For the o96 resolution, default per-gpu batch_size is 2 (8 gpus required)
# The global lr is calculated as:
# global_lr = local_lr * num_gpus_per_node * num_nodes / gpus_per_model
# Assuming a constant effective batch_size, any change in the per_gpu batch_size
# should come with a rescaling of the local_lr to keep a constant global_lr
# ============

# runs only N training batches [N = integer | null]
# if null then we run through all the batches
limit_batches:
  training: null
  validation: 10 #null
  test: 20
  predict: 20

# set a custom mask for grid points.
# Useful for LAM (dropping unconnected nodes from forcing dataset)
grid_indices:
  _target_: anemoi.training.data.grid_indices.FullGrid
  nodes_name: ${graph.data}

# ============
# Dataloader definitions
# These follow the anemoi-datasets patterns
# You can make these as complicated for merging as you like
# See https://anemoi-datasets.readthedocs.io
# ============
select: 
      - 2t
      - 2d
      - 10u
      - 10v
      - msl
      - sp
      - lsm
      - z
      - tp
      - u_100
      - u_150
      - u_200
      - u_300
      - u_400
      - u_500
      - u_700
      - u_850
      - u_925
      - u_1000
      # - v_100
      # - v_150
      # - v_200
      # - v_300
      # - v_400
      # - v_500
      # - v_700
      # - v_850
      # - v_925
      # - v_1000
      # - w_100
      # - w_150
      # - w_200
      # - w_300
      # - w_400
      # - w_500
      # - w_700
      # - w_850
      # - w_925
      # - w_1000
      # - t_100
      # - t_150
      # - t_200
      # - t_300
      # - t_400
      # - t_500
      # - t_700
      # - t_850
      # - t_925
      # - t_1000
      # - q_100
      # - q_150
      # - q_200
      # - q_300
      # - q_400
      # - q_500
      # - q_700
      # - q_850
      # - q_925
      # - q_1000
      # - z_100
      # - z_150
      # - z_200
      # - z_300
      # - z_400
      # - z_500
      # - z_700
      # - z_850
      # - z_925
      # - z_1000
      - "cos_latitude"
      - "cos_longitude"
      - "sin_latitude"
      - "sin_longitude"
      - "cos_julian_day"
      - "cos_local_time"
      - "sin_julian_day"
      - "sin_local_time"
      - "insolation"
# #new
# training_periods:
#   MEPS:
#     start: 2020-02-05 
#     end: 2023-05-31
#   # ARA:
#   #   start: 2012-01-01
#   #   end: 2015-12-31

# #new
# validation_periods:
#   MEPS:
#     start: 2023-06-01
#     end: 2024-05-31
#   # ARA:
#   #   start: 2016-01-01
#   #   end: 2016-12-31

# # new
# regional_datasets:
#   MEPS: 
#     dataset: /pfs/lustrep4/scratch/project_465000527/anemoi/datasets/MEPS/aifs-meps-2.5km-2020-2024-6h-v6.zarr
#   # ARA: 
#   #   dataset: /pfs/lustrep4/scratch/project_465000527/ARA_Data/Zarr/aut-rd-an-oper-0001-ara-2p5km-20120101_20181231-3h-v7.zarr

# global:         
#   concat:
#     - dataset: ${hardware.paths.data}/aifs-ea-an-oper-0001-mars-o96-1979-2022-6h-v6.zarr
#       start: null
#       end: 2021-12-31
#     - dataset: ${hardware.paths.data}/aifs-od-an-oper-0001-mars-o96-2016-2023-6h-v6.zarr
#       start: 2022-01-01
#       end: 2023-12-31
# #new
# datasets:
#   cutout:
#     - dataset: null 
#       select: ${dataloader.select}
#     - dataset: ${dataloader.global}
#       select: ${dataloader.select}
#   adjust: ["all"]
#   statistics: ${hardware.paths.data}/aifs-ea-an-oper-0001-mars-o96-1979-2022-6h-v6.zarr

# graph_datasets: 
#   MEPS:
#     cutout:
#       - dataset: /pfs/lustrep4/scratch/project_465000527/anemoi/datasets/MEPS/aifs-meps-2.5km-2020-2024-6h-v6.zarr
#         select: ${dataloader.select}
#       - dataset: ${hardware.paths.data}/${hardware.files.dataset}
#         select: ${dataloader.select}
#     adjust: "all" #all
#     # reorder: sort
#     # start: null
#     # end: null
#     statistics: ${hardware.paths.data}/${hardware.files.dataset}
#     min_distance_km: 20
    
#   ARA:
#     cutout:
#       - dataset: /pfs/lustrep4/scratch/project_465000527/ARA_Data/Zarr/aut-rd-an-oper-0001-ara-2p5km-20120101_20181231-3h-v7.zarr
#         select: ${dataloader.select}
#       - dataset: ${hardware.paths.data}/${hardware.files.dataset}
#         select: ${dataloader.select}
#     adjust: "all" #all
#     #reorder: sort
#     min_distance_km: 20
#     #start: null
#     #end: null
    


# TODO: fix validation start and end
# TODO: Make the dataset key more tidier for train and val

training:
  dataset: ${dataloader.datasets}
  #new
  #period: ${training_periods} #null # <- dict of of train periods
  
  # old
  start: null # inject start date in pre-process
  end: null # inject end date in pre-process
  #frequency: ${data.frequency}
  #drop:  []

validation_rollout: 1 # number of rollouts to use for validation, must be equal or greater than rollout expected by callbacks

validation:
  dataset: ${dataloader.datasets}
  #new
  #period: ${validation_periods} #null # <- dict of of train periods
  start: null # inject start date in pre-process
  end: null # inject end date in pre-process
  #frequency: ${data.frequency}
  #drop:  []

test:
  dataset: ${dataloader.datasets}
  start: 2022
  end: null
  #frequency: ${data.frequency}
